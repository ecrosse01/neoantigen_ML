{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate and process the different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set directories\n",
    "SRSF2_2 = Training set with known positive control binders\n",
    "SRSF2_9 = Test set with known true binders\n",
    "SRSF2_10 = Test set - noisy with no confirmed binders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Label distribution (1 = true binder):\n",
      "is_true_binder\n",
      "0    400859\n",
      "1       241\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def set_directories(patient_id, base_dir):\n",
    "    \"\"\"\n",
    "    Generate a dictionary containing paths to relevant directories for a given patient.\n",
    "    \n",
    "    Parameters:\n",
    "    - patient_id (str): The unique identifier for the patient.\n",
    "    - base_dir (str): The base directory containing all patient data.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary with paths to gene expression, dextramer, TCR, and CITE-seq data.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"dir_gex\": os.path.join(base_dir, f\"{patient_id}/CellRangerGex_results\"),\n",
    "        \"dir_dex\": os.path.join(base_dir, f\"{patient_id}_dextramer_count/umi_count\"),\n",
    "        \"dir_TCR\": os.path.join(base_dir, f\"{patient_id}_TCR_VDJ/CellRangerVdj_results\"),\n",
    "        \"dir_CITE\": os.path.join(base_dir, f\"{patient_id}_hash_count/umi_count\")\n",
    "    }\n",
    "\n",
    "# Define base directory and patient IDs\n",
    "base_dir = \"/Users/ecrosse/Desktop/\"\n",
    "\n",
    "# Set directories for each patient\n",
    "dirs_SRSF2_2 = set_directories(\"november_dextramer_data/WJK-2719_SRSF2_2\", base_dir)\n",
    "dirs_SRSF2_9 = set_directories(\"data_for_edie_third_batch_january/WJK-2859_SRSF2_9\", base_dir)\n",
    "#dirs_SRSF2_10 = set_directories(\"data_for_edie_third_batch_january/WJK-2859_SRSF2_10\", base_dir)\n",
    "\n",
    "\n",
    "# Print to verify the directory structure\n",
    "print(dirs_SRSF2_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data integration and processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_adata(dirs):\n",
    "    # Unpack paths\n",
    "    dir_gex, dir_dex, dir_CITE, dir_TCR = (\n",
    "        dirs[\"dir_gex\"], dirs[\"dir_dex\"], dirs[\"dir_CITE\"], dirs[\"dir_TCR\"]\n",
    "    )\n",
    "\n",
    "    # Load gene expression\n",
    "    adata = sc.read_10x_h5(os.path.join(dir_gex, \"filtered_feature_bc_matrix.h5\"))\n",
    "    adata.var_names_make_unique()\n",
    "\n",
    "    # Load CITE-seq\n",
    "    cite_matrix = scipy.io.mmread(f\"{dir_CITE}/matrix.mtx.gz\").T.tocsr()\n",
    "    cite_barcodes = pd.read_csv(f\"{dir_CITE}/barcodes.tsv.gz\", header=None, sep='\\t')[0].values + \"-1\"\n",
    "    cite_features = pd.read_csv(f\"{dir_CITE}/features.tsv.gz\", header=None, sep='\\t')[1].values\n",
    "\n",
    "    # Load Dextramer\n",
    "    dex_matrix = scipy.io.mmread(f\"{dir_dex}/matrix.mtx.gz\").T.tocsr()\n",
    "    dex_barcodes = pd.read_csv(f\"{dir_dex}/barcodes.tsv.gz\", header=None, sep='\\t')[0].values + \"-1\"\n",
    "    dex_features = pd.read_csv(f\"{dir_dex}/features.tsv.gz\", header=None, sep='\\t')[1].values\n",
    "\n",
    "    # Intersect barcodes\n",
    "    common = list(set(adata.obs_names) & set(cite_barcodes) & set(dex_barcodes))\n",
    "    adata = adata[adata.obs_names.isin(common)].copy()\n",
    "\n",
    "    # Align barcode indices\n",
    "    cite_idx = np.array([np.where(cite_barcodes == bc)[0][0] for bc in adata.obs_names])\n",
    "    dex_idx = np.array([np.where(dex_barcodes == bc)[0][0] for bc in adata.obs_names])\n",
    "    adata.obsm[\"CITE\"] = cite_matrix[cite_idx, :]\n",
    "    adata.obsm[\"Dextramer\"] = dex_matrix[dex_idx, :]\n",
    "    adata.uns[\"CITE_features\"] = cite_features\n",
    "    adata.uns[\"Dextramer_features\"] = dex_features\n",
    "\n",
    "    # QC + normalization\n",
    "    adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], inplace=True)\n",
    "    sc.pp.filter_cells(adata, min_genes=250)\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "    sc.pp.filter_cells(adata, min_counts=500)\n",
    "    adata.layers[\"counts\"] = adata.X.copy()\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=4000)\n",
    "    adata.var[\"highly_variable\"] &= ~adata.var_names.str.startswith(\"TR\")\n",
    "    sc.pp.scale(adata, max_value=10)\n",
    "\n",
    "    # TCR clonotype integration\n",
    "    vdj = pd.read_csv(f\"{dir_TCR}/filtered_contig_annotations.csv\")\n",
    "    tcr = vdj[\n",
    "        (vdj[\"high_confidence\"]) &\n",
    "        (vdj[\"productive\"]) &\n",
    "        (vdj[\"chain\"].isin([\"TRA\", \"TRB\"])) &\n",
    "        (vdj[\"umis\"] >= 3)\n",
    "    ][[\"barcode\", \"chain\", \"raw_clonotype_id\"]]\n",
    "    tcr = tcr.groupby(\"raw_clonotype_id\").filter(lambda g: {\"TRA\", \"TRB\"}.issubset(set(g[\"chain\"])))\n",
    "    tcr = tcr.reset_index(drop=True)\n",
    "\n",
    "    clono = pd.read_csv(f\"{dir_TCR}/clonotypes.csv\")[[\"clonotype_id\", \"cdr3s_aa\", \"cdr3s_nt\"]]\n",
    "    clono = clono.rename(columns={\"clonotype_id\": \"raw_clonotype_id\"})\n",
    "    tcr = tcr.merge(clono, on=\"raw_clonotype_id\", how=\"left\")\n",
    "\n",
    "    clonotype_info = tcr[[\"barcode\", \"raw_clonotype_id\"]].drop_duplicates().set_index(\"barcode\")\n",
    "    adata.obs = adata.obs.join(clonotype_info, how=\"left\")\n",
    "\n",
    "    # CITE CLR transform (but no thresholding yet)\n",
    "    def clr_transform(matrix, eps=1e-9):\n",
    "        if sp.issparse(matrix): matrix = matrix.toarray()\n",
    "        gm = np.exp(np.mean(np.log(matrix + eps), axis=1, keepdims=True))\n",
    "        return np.log((matrix + eps) / (gm + eps))\n",
    "\n",
    "    adata.obsm[\"CITE_clr\"] = clr_transform(adata.obsm[\"CITE\"])\n",
    "\n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply to a sample and find manual CITE-Seq threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = load_and_prepare_adata(dirs_SRSF2_2)\n",
    "\n",
    "# Then inspect hash distribution\n",
    "hash_idx = np.where(adata.uns[\"CITE_features\"] == \"Hash\")[0][0]\n",
    "hash_values = adata.obsm[\"CITE_clr\"][:, hash_idx]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.histplot(hash_values, kde=True, bins=50)\n",
    "plt.xlabel(\"CLR-transformed Hash expression\")\n",
    "plt.title(\"Hash Histogram\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply threshold to define Dex+ cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_adata_after_hash(adata, hash_cutoff=0.8):\n",
    "    # Locate \"Hash\" feature index\n",
    "    hash_idx = np.where(adata.uns[\"CITE_features\"] == \"Hash\")[0][0]\n",
    "    \n",
    "    # Extract CLR-transformed Hash counts\n",
    "    hash_vals = adata.obsm[\"CITE_clr\"][:, hash_idx]\n",
    "    adata.obs[\"HashCounts\"] = hash_vals\n",
    "\n",
    "    # Assign manual hash demux label\n",
    "    adata.obs[\"manual_hash_dmux\"] = np.where(hash_vals > hash_cutoff, \"CITE_hash\", \"Negative\")\n",
    "\n",
    "    # Remove \"unmapped\" dextramer feature\n",
    "    unmapped_idx = np.where(adata.uns[\"Dextramer_features\"] == \"unmapped\")[0]\n",
    "    if unmapped_idx.size > 0:\n",
    "        adata.uns[\"Dextramer_features\"] = np.delete(adata.uns[\"Dextramer_features\"], unmapped_idx[0])\n",
    "        adata.obsm[\"Dextramer\"] = sp.csr_matrix(\n",
    "            np.delete(adata.obsm[\"Dextramer\"].toarray(), unmapped_idx[0], axis=1)\n",
    "        )\n",
    "\n",
    "    # Add total dextramer counts\n",
    "    adata.obs[\"Dextramer_total_counts\"] = adata.obsm[\"Dextramer\"].sum(axis=1)\n",
    "\n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"adata_SRSF2_2_processed.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
